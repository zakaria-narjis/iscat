{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb878998-a2d7-46a1-8e85-754bf287bca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /workspace/iscat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(\"Current Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d3c1b34-f944-42df-851e-e44b0dc00e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41350, 16, 201)\n",
      "(array([0, 1, 2, 3]), array([32462,  8659,    60,   169]))\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "particle_data_path ='dataset/brightfield_particles.hdf5'\n",
    "with h5py.File(particle_data_path , 'r') as f:\n",
    "    print(f['data'].shape)\n",
    "    print(np.unique(f['labels'],return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44bc0f64-885b-462a-9195-4cadf599f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "import numpy as np\n",
    "# from torchvision.models import vit_b_16\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from torchvision.models.vision_transformer import VisionTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import confusion_matrix, f1_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd537f06-96fd-4319-91e9-dc4f28657147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2    \n",
    "def compute_normalization_stats(h5_path, classes=None):\n",
    "    \"\"\"\n",
    "    Compute mean and standard deviation for z-score normalization.\n",
    "    \n",
    "    Args:\n",
    "        h5_path (str): Path to HDF5 file\n",
    "        classes (list, optional): List of classes to include in computation\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mean, std) computed across all data points\n",
    "    \"\"\"\n",
    "    with h5py.File(h5_path, 'r') as h5_file:\n",
    "        data = h5_file['data'][:]\n",
    "        labels = h5_file['labels'][:]\n",
    "        \n",
    "        if classes is not None:\n",
    "            # Filter data for selected classes\n",
    "            mask = np.isin(labels, classes)\n",
    "            data = data[mask]\n",
    "        \n",
    "        # Compute statistics across all dimensions\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        \n",
    "        print(f\"Computed statistics: mean = {mean:.4f}, std = {std:.4f}\")\n",
    "        \n",
    "        return mean, std\n",
    "        \n",
    "class ParticleDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for particle data with flexible class selection and normalization.\"\"\"\n",
    "    def __init__(self, h5_path, classes=[0, 1], transform=None, mean=None, std=None,padding=False,indices=None):\n",
    "        self.h5_file = h5py.File(h5_path, 'r')\n",
    "        data = self.h5_file['data'][:]\n",
    "        labels = self.h5_file['labels'][:]\n",
    "        self.padding = padding\n",
    "        # Filter data for selected classes\n",
    "        mask = np.isin(labels, classes)\n",
    "        if indices is None:\n",
    "            self.data = data[mask][:]\n",
    "            self.labels = labels[mask][:] \n",
    "        else:\n",
    "            self.data = data[mask][indices]\n",
    "            self.labels = labels[mask][indices]\n",
    "        \n",
    "        # Create class mapping to handle non-consecutive class indices\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "        self.num_classes = len(classes)\n",
    "        \n",
    "        # Map original labels to new consecutive indices\n",
    "        self.labels = np.array([self.class_to_idx[label] for label in self.labels])\n",
    "        self.transform = transform\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get particle data\n",
    "        particle = self.data[idx]  # Shape: (16, 201)\n",
    "        \n",
    "        # Apply normalization if mean and std are provided\n",
    "        if self.mean is not None and self.std is not None:\n",
    "            particle = (particle - self.mean) / self.std\n",
    "        \n",
    "        # Convert to torch tensor for better interpolation\n",
    "        particle_tensor = torch.FloatTensor(particle).unsqueeze(0)  # Add channel dim\n",
    "        \n",
    "        # Resize to (16, 16) using bicubic interpolation\n",
    "        resized = torch.nn.functional.interpolate(\n",
    "            particle_tensor.unsqueeze(0),  # Add batch dim\n",
    "            size=(16, 201),\n",
    "            mode='bicubic',\n",
    "            align_corners=True\n",
    "        ).squeeze(0).squeeze(0)  # Remove batch and channel dims\n",
    "        \n",
    "        final_tensor = resized.unsqueeze(0).repeat(3, 1, 1)  # Repeat across 3 channels\n",
    "        \n",
    "        if self.transform:\n",
    "            final_tensor = self.transform(final_tensor)\n",
    "        \n",
    "        # Create one-hot encoded label\n",
    "        label_idx = self.labels[idx]\n",
    "        # label_onehot = torch.zeros(self.num_classes)\n",
    "        # label_onehot[label_idx] = 1\n",
    "        \n",
    "        # return final_tensor, label_onehot\n",
    "        return final_tensor , label_idx\n",
    "    def close(self):\n",
    "        self.h5_file.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb2cddf3-50b0-451e-8d94-3c50397f6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def distance_matrix(a, b):\n",
    "    a_expanded = a.view(-1, 1)\n",
    "    b_expanded = b.view(1, -1)\n",
    "\n",
    "    return torch.abs(a_expanded - b_expanded)\n",
    "\n",
    "def knn_divergence(points_x, points_y, k, smoothing_kernel=None):\n",
    "    xx_distances = distance_matrix(points_x, points_x)\n",
    "    xy_distances = distance_matrix(points_x, points_y) # one row for every sample in x, one col for every sample in y\n",
    "\n",
    "    # if the sets have different sizes\n",
    "    # e.g. y has twice as many points -> the distance to the 3rd closest point in x should be the same as the distance to the 6th point in y\n",
    "    k_multiplier = points_y.shape[0] / points_x.shape[0]\n",
    "\n",
    "    k_dist_xx = torch.sort(xx_distances, dim=1)[0][:, k]\n",
    "    k_dist_xy = torch.sort(xy_distances, dim=1)[0][:, (k * k_multiplier).to(torch.int)]\n",
    "    # optional: smoothen the distances \n",
    "    # (so that it matters less whether a point is the i-th or the (i+1)-th closest neighbor)\n",
    "    if smoothing_kernel != None:\n",
    "            # torch conv1d demands a channel dimension, hence the (un)squeezing\n",
    "            k_dist_xx = torch.nn.functional.conv1d(k_dist_xx.unsqueeze(1), weight=smoothing_kernel.view(1, 1, -1)).flatten(1)\n",
    "            k_dist_xy = torch.nn.functional.conv1d(k_dist_xy.unsqueeze(1), weight=smoothing_kernel.view(1, 1, -1)).flatten(1)\n",
    "\n",
    "    # return torch.mean((1 - k_dist_xx / k_dist_xy)**2)\n",
    "    return torch.mean((k_dist_xx - k_dist_xy)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba9b1e5-934f-44bb-aebc-9302037fca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def generate_label_distribution(num_points=10000, mean=76, std=22.5, min_value=10, max_value=None):\n",
    "    \"\"\"\n",
    "    Generate a tensor of points sampled from a normal distribution with specified mean and standard deviation\n",
    "    while rejecting points outside the optional min and max value constraints.\n",
    "    \n",
    "    Args:\n",
    "        num_points (int): Number of points to generate\n",
    "        mean (float): Mean of the distribution\n",
    "        std (float): Standard deviation of the distribution\n",
    "        min_value (float, optional): Minimum value of the distribution (inclusive)\n",
    "        max_value (float, optional): Maximum value of the distribution (inclusive)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Tensor of generated points within the specified range\n",
    "    \"\"\"\n",
    "    points = torch.empty(0)  # Initialize an empty tensor to store valid points\n",
    "\n",
    "    while points.numel() < num_points:\n",
    "        # Generate points from normal distribution\n",
    "        generated_points = torch.normal(mean=mean, std=std, size=(num_points,))\n",
    "        \n",
    "        # Filter points based on the min and max values\n",
    "        if min_value is not None:\n",
    "            generated_points = generated_points[generated_points >= min_value]\n",
    "        if max_value is not None:\n",
    "            generated_points = generated_points[generated_points <= max_value]\n",
    "        \n",
    "        # Add the valid points to the tensor\n",
    "        points = torch.cat((points, generated_points))\n",
    "    # Return only the first `num_points` points\n",
    "    return points[:num_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ced2fa-7cb7-41fb-bac6-6f267e46debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "# resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "# # resnet .fc = nn.Linear(resnet.fc.in_features, 1)\n",
    "# resnet .fc = nn.Sequential(\n",
    "#     nn.Linear(resnet.fc.in_features, 32),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(32, 1))\n",
    "# summary(resnet, input_size=(3, 16, 201),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d414e4-aee4-42ef-a922-7bbda00008f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:11\n",
      "Computed statistics: mean = 7537.6143, std = 1312.3260\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(42)\n",
    "DEVICE = \"cuda:11\"\n",
    "# Device configuration\n",
    "device = torch.device(DEVICE if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "# classes = [0]\n",
    "transform = v2.Compose([\n",
    "    v2.RandomVerticalFlip(p=0.5),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "])\n",
    "\n",
    "mean, std = compute_normalization_stats('dataset/brightfield_particles.hdf5', classes=[0,1])\n",
    "batch_size_80 = 10000\n",
    "num_points_80 = 30000\n",
    "batch_size_300 = 8192\n",
    "num_points_300 = 20000\n",
    "\n",
    "dataset_80 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                            classes=[0],\n",
    "                            mean=mean,\n",
    "                            std=std,\n",
    "                            padding=True,\n",
    "                            transform = transform,\n",
    "                            indices=list(range(0, 30000)),\n",
    "                         )\n",
    "dataset_300 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                            classes=[1],\n",
    "                            mean=mean,\n",
    "                            std=std,\n",
    "                            padding=True,\n",
    "                            transform = transform,\n",
    "                            indices=list(range(0, 8192)),\n",
    "                         )\n",
    "# batch_size = 10000\n",
    "# num_points = 30000\n",
    "dataloader_80 = DataLoader(dataset_80, batch_size=batch_size_80 , shuffle=True)\n",
    "label_points_80 = generate_label_distribution(num_points_80, mean=76, std=22.5)\n",
    "\n",
    "dataloader_300 = DataLoader(dataset_300, batch_size=batch_size_300 , shuffle=True)\n",
    "label_points_300 = generate_label_distribution(num_points_300, mean=302, std=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e9fc85-2b2f-4665-a1aa-b0d9c9a19d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(model, dataloaders, label_points, device, num_epochs=10, learning_rate=0.1,class_loss=True): #3e-2\n",
    "    \"\"\"\n",
    "    Train ResNet model using KNN divergence loss with early stopping and learning rate scheduling.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): ResNet model\n",
    "        dataloader (torch.utils.data.DataLoader): Training dataloader\n",
    "        label_points (torch.Tensor): Pre-generated label points\n",
    "        device (torch.device): Device to train on\n",
    "        num_epochs (int): Number of training epochs\n",
    "        learning_rate (float): Learning rate for optimizer\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        best_loss: Best training loss achieved\n",
    "    \"\"\"\n",
    "    if class_loss:\n",
    "        loss_weights = len(dataloaders[0].dataset)/len(dataloaders[1].dataset)\n",
    "        loss_weights = torch.Tensor([loss_weights]).to(device)\n",
    "        bceloss = torch.nn.BCEWithLogitsLoss(pos_weight=loss_weights)\n",
    "    # Move label points to the specified device\n",
    "    labels = [label.to(device, non_blocking=True) for label in label_points] \n",
    "    # labels_80, labels_300 = labels[0],labels[1] \n",
    "    # Prepare k values for KNN divergence\n",
    "    ks = [torch.arange(2, 1000//10, dtype=torch.int) for label_point in label_points]    \n",
    "    # Setup optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Setup learning rate scheduler with patience of 8\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', patience=8, factor=0.5\n",
    "    )\n",
    "    \n",
    "    model.to(device)\n",
    "   \n",
    "    # Early stopping parameters\n",
    "    best_loss = float('inf')\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        accuracy = 0\n",
    "        for idx, (label, dataloader) in enumerate(zip(labels, dataloaders)):\n",
    "                for batch_images, _ in dataloader:\n",
    "                    batch_count += 1\n",
    "                    gt = torch.clone(label)\n",
    "                    batch_images = batch_images.to(device)\n",
    "                    \n",
    "                    # Zero gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # Forward pass: generate predictions\n",
    "                    if class_loss:\n",
    "                        batch_predictions, pred_class= model(batch_images)\n",
    "                        gt_class = torch.full(pred_class.shape, idx, dtype=torch.float, device=device)\n",
    "                        loss = knn_divergence(batch_predictions, gt, ks[idx])\n",
    "                        loss += bceloss(pred_class,pred_class)  \n",
    "                        logits = torch.sigmoid(pred_class)\n",
    "                        accuracy += (gt_class == (logits > 0.5).float()).sum().item()\n",
    "\n",
    "                    else:\n",
    "                        batch_predictions= model(batch_images)\n",
    "                        loss = knn_divergence(batch_predictions, gt, ks[idx])\n",
    "\n",
    "                    # Backward pass and optimize\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = total_loss / batch_count\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        if class_loss :\n",
    "            total_samples = sum(len(d.dataset) for d in dataloaders)\n",
    "            accuracy = accuracy / total_samples\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {current_lr:.2e}, Accuracy {accuracy:.2e}')\n",
    "        else:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, LR: {current_lr:.2e}')\n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping triggered after {epoch + 1} epochs')\n",
    "                # Restore best model\n",
    "                model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    \n",
    "    return model, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45e7991-5310-4387-aec5-88e8846a99a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResNetDualHead(nn.Module):\n",
    "    def __init__(self, class_head=False):\n",
    "        super(ResNetDualHead, self).__init__()\n",
    "        \n",
    "        self.backbone = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=None)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        # Regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(in_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        self.class_head = class_head\n",
    "        if class_head:\n",
    "            # Classification head (binary classification)\n",
    "            self.classification_head = nn.Sequential(\n",
    "                nn.Linear(in_features, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)  # Binary classification (logits)\n",
    "            )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone.forward(x)\n",
    "        regression_output = self.regression_head(features)\n",
    "        \n",
    "        if self.class_head:\n",
    "            classification_output = self.classification_head(features)\n",
    "            return regression_output, classification_output\n",
    "        \n",
    "        return regression_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9b31a67-7dae-46ea-8df3-9e59d59a8d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "BCELoss.__init__() got an unexpected keyword argument 'pos_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m label_points \u001b[38;5;241m=\u001b[39m (label_points_80,label_points_300)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# resnet .fc = nn.Linear(resnet.fc.in_features, 1)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m resnet,best_loss \u001b[38;5;241m=\u001b[39m train_resnet(resnet, dataloaders, label_points, device, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m     14\u001b[0m resnet\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m, in \u001b[0;36mtrain_resnet\u001b[0;34m(model, dataloaders, label_points, device, num_epochs, learning_rate, class_loss)\u001b[0m\n\u001b[1;32m     18\u001b[0m     loss_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloaders[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloaders[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     19\u001b[0m     loss_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([loss_weights])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 20\u001b[0m     bceloss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCELoss(pos_weight\u001b[38;5;241m=\u001b[39mloss_weights)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Move label points to the specified device\u001b[39;00m\n\u001b[1;32m     22\u001b[0m labels \u001b[38;5;241m=\u001b[39m [label\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m label_points] \n",
      "\u001b[0;31mTypeError\u001b[0m: BCELoss.__init__() got an unexpected keyword argument 'pos_weight'"
     ]
    }
   ],
   "source": [
    "# resnet = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=None)\n",
    "# resnet .fc = nn.Sequential(\n",
    "#     nn.Linear(resnet.fc.in_features, 128),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(128, 64),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(64, 1)\n",
    "# )\n",
    "resnet =  ResNetDualHead(class_head=True)\n",
    "dataloaders = (dataloader_80,dataloader_300)\n",
    "label_points = (label_points_80,label_points_300)\n",
    "# resnet .fc = nn.Linear(resnet.fc.in_features, 1)\n",
    "resnet,best_loss = train_resnet(resnet, dataloaders, label_points, device, num_epochs=300)\n",
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50403a-d1fb-48db-8f94-bd4ecdc2cb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "resnet(dataset_80[0][0].unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6ed8f-4812-4f11-bf7f-dfacc6aa106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_80 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                          classes=[0],\n",
    "                          mean=mean,\n",
    "                          std=std,\n",
    "                          padding=True,\n",
    "                        transform = None,\n",
    "                        indices = None\n",
    "                         )\n",
    "plot_dataloader_80 = DataLoader(plot_dataset_80  , batch_size=len(plot_dataset_80 ))\n",
    "with torch.no_grad():\n",
    "    out= next(iter(dataloader_80))[0]\n",
    "    out  = resnet(out.to(device)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f318c5-e760-445f-89e7-2204afb38d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0433e3-4879-4299-803b-9b70aa230b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(label_points_80 , bins=50, alpha=0.6, label='Ground Truth', color='blue', density=True)\n",
    "plt.hist(out, bins=50, alpha=0.6, label='Prediction', color='red', density=True)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('Diamerter[nm]')\n",
    "plt.ylabel('Density[norm.]')\n",
    "plt.title('Ground Truth vs Prediction Distribution_80nm')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ec387-8e2c-49ab-af56-44bd3b8fe702",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_300 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                          classes=[1],\n",
    "                          mean=mean,\n",
    "                          std=std,\n",
    "                          padding=True,\n",
    "                        transform = None,\n",
    "                        indices = None\n",
    "                         )\n",
    "plot_dataloader_300 = DataLoader(plot_dataset_300 , batch_size=len(plot_dataset_300))\n",
    "with torch.no_grad():\n",
    "    out_2 = next(iter(plot_dataloader_300))[0]\n",
    "    out_2  = resnet(out_2.to(device)).cpu().detach().numpy()\n",
    "label_points_300 = generate_label_distribution(len(plot_dataset_300), mean=302, std=25)\n",
    "print(out_2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883cd88-2497-40e1-9b8d-910f5ab1d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Example list of values\n",
    "# values =out_2+(302-out_2.mean())\n",
    "values =out_2\n",
    "# values = o\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(values, bins=50, color='red',label='Prediction',alpha=0.7, density=True)\n",
    "plt.hist(label_points_300  , bins=50, alpha=0.6, label='Ground Truth', color='blue', density=True)\n",
    "# Add labels\n",
    "# Labels and legend\n",
    "plt.xlabel('Diamerter[nm]')\n",
    "plt.ylabel('Density[norm.]')\n",
    "plt.title('Ground Truth vs Prediction Distribution_300nm')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d3d88-0e70-4e1e-aad6-bf5685e7333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_300 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                          classes=[3],\n",
    "                          mean=mean,\n",
    "                          std=std,\n",
    "                          padding=True,\n",
    "                        transform = None,\n",
    "                        indices=None\n",
    "                         )\n",
    "plot_dataloader_300 = DataLoader(plot_dataset_1300, batch_size=len(plot_dataset_300))\n",
    "with torch.no_grad():\n",
    "    out_3 = next(iter(plot_dataloader_300))[0]\n",
    "    out_3  = resnet(out_3.to(device)).cpu().detach().numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example list of values\n",
    "values = out_3\n",
    "# values = o\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(values, bins=50, density=True, color='blue', alpha=0.7)\n",
    "\n",
    "# Add labels\n",
    "plt.title('Distribution of Values_1300nm')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb1c84-8237-4268-8cd7-be87607073d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset_80 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                          classes=[0],\n",
    "                          mean=mean,\n",
    "                          std=std,\n",
    "                          padding=True,\n",
    "                            transform = None,indices=list(range(0, 30000))\n",
    "                         )\n",
    "plot_dataloader_80 = DataLoader(plot_dataset_80, batch_size=30000)\n",
    "with torch.no_grad():\n",
    "    out_4 = next(iter(plot_dataloader_80))[0]\n",
    "    out_4  = resnet(out_4.to(device)).cpu().detach().numpy()\n",
    "import matplotlib.pyplot as plt\n",
    "# Example list of values\n",
    "values = out_4\n",
    "# values = o\n",
    "# Set up the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(label_points_80 , bins=50, alpha=0.6, label='Ground Truth', color='blue', density=True)\n",
    "plt.hist(values, bins=50, density=True, color='red', alpha=0.6)\n",
    "\n",
    "# Add labels\n",
    "plt.title('Distribution of Values_80nm')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95ec40-8ff0-45c3-92da-06fa8aa16e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "values.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d8064-0bdd-4a18-9fec-61148331e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output_map = resnet.conv1(dataset_80[0][0].unsqueeze(0).to(device)).squeeze(0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc3170-d622-4221-8449-cf2f6a915198",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 10))\n",
    "f=torch.clone(output_map[3])\n",
    "# f[f<(f.mean())]=0\n",
    "ax.imshow(f,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa5d029-fd07-40ff-9bd5-66a626d800d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    imgs = next(iter(plot_dataloader_80))[0]  # (10000,3,16,201)\n",
    "    img = imgs[2000].unsqueeze(0)  # (1,3,16,201)\n",
    "    \n",
    "    # Get prediction for original image\n",
    "    size_1 = resnet(img.to(device)).cpu()\n",
    "    size_1 = size_1.squeeze(0)\n",
    "    \n",
    "    # Flip the image horizontally (along the last dimension)\n",
    "    img_flipped = torch.flip(img, dims=[-1])\n",
    "    \n",
    "    # Get prediction for flipped image\n",
    "    size_2 = resnet(img_flipped.to(device)).cpu()\n",
    "    size_2 = size_2.squeeze(0)\n",
    "    \n",
    "    # Print both predictions\n",
    "    print(f\"Original image size prediction: {size_1.item():.3f}\")\n",
    "    print(f\"Flipped image size prediction: {size_2.item():.3f}\")\n",
    "    print(f\"Absolute difference: {abs(size_1.item() - size_2.item()):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220a167-dfa9-4632-8562-3b899edca031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_dataset_80 = ParticleDataset(h5_path='dataset/brightfield_particles.hdf5',\n",
    "                          classes=[0],\n",
    "                          mean=mean,\n",
    "                          std=std,\n",
    "                          padding=True,\n",
    "                            transform = None\n",
    "                         )\n",
    "plot_dataloader = DataLoader(plot_dataset_80, batch_size=batch_size)\n",
    "with torch.no_grad():\n",
    "    imgs = next(iter(plot_dataloader))[0]  # (10000,3,16,201)\n",
    "    sizes = resnet(imgs.to(device)).cpu() \n",
    "    \n",
    "max_size, max_idx = sizes.max(dim=0)\n",
    "min_size, min_idx = sizes.min(dim=0)\n",
    "\n",
    "# Compute middle size (median)\n",
    "mid_size = sizes.median()\n",
    "mid_idx = (sizes - mid_size).abs().argmin()\n",
    "mid_idx = torch.tensor([mid_idx], dtype=torch.int64)\n",
    "\n",
    "# Create 9 intermediate values between min, mid, and max\n",
    "intermediate_sizes, intermediate_indices = [], []\n",
    "for fraction in torch.linspace(0, 1, steps=9):\n",
    "    interp_size = min_size + fraction * (max_size - min_size)\n",
    "    closest_idx = (sizes - interp_size).abs().argmin()\n",
    "    intermediate_sizes.append(sizes[closest_idx])\n",
    "    intermediate_indices.append(closest_idx)\n",
    "\n",
    "# Convert indices to tensor\n",
    "intermediate_indices = torch.tensor(intermediate_indices, dtype=torch.int64)\n",
    "\n",
    "# Get images and resize them\n",
    "resized_images = [\n",
    "    torch.nn.functional.interpolate(\n",
    "        imgs[idx][0:1].unsqueeze(0), size=(16, 32), mode=\"bilinear\", align_corners=False\n",
    "    ).squeeze(0)[0]\n",
    "    for idx in intermediate_indices\n",
    "]\n",
    "\n",
    "# Create 3x3 subplot\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 9))\n",
    "\n",
    "# Plot images\n",
    "for ax, img, size in zip(axes.flat, resized_images, intermediate_sizes):\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.title.set_text(f\"size: {size.item()}\")\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9080f11f-db17-457f-9c69-6a7a5d8bad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import contextlib\n",
    "import torch.nn.functional as F\n",
    "model = resnet\n",
    "def remove_all_hooks(model):\n",
    "    \"\"\"Removes all forward and backward hooks from the model.\"\"\"\n",
    "    for module in model.modules():  \n",
    "        if hasattr(module, \"_forward_hooks\"):\n",
    "            module._forward_hooks.clear()\n",
    "        if hasattr(module, \"_backward_hooks\"):\n",
    "            module._backward_hooks.clear()\n",
    "        if hasattr(module, \"_full_backward_hooks\"):\n",
    "            module._full_backward_hooks.clear()\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.feature_maps = None\n",
    "        self.gradient = None\n",
    "        \n",
    "        self.target_layer.register_forward_hook(self._save_feature_maps)\n",
    "        self.target_layer.register_full_backward_hook(self._save_gradient)\n",
    "    \n",
    "    def _save_feature_maps(self, module, input, output):\n",
    "        self.feature_maps = output.detach()\n",
    "    \n",
    "    def _save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradient = grad_output[0].detach()\n",
    "    \n",
    "    def generate_heatmap(self, input_image, target_index=None):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get model prediction\n",
    "        output = self.model(input_image)\n",
    "        \n",
    "        if target_index is None:\n",
    "            target = output\n",
    "        else:\n",
    "            target = output[:, target_index]\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        target.backward()\n",
    "        \n",
    "        # Calculate weights\n",
    "        weights = torch.mean(self.gradient, dim=(2, 3), keepdim=True)\n",
    "        \n",
    "        # Generate weighted combination of feature maps\n",
    "        cam = torch.sum(weights * self.feature_maps, dim=1, keepdim=True)\n",
    "        \n",
    "        # Apply ReLU\n",
    "        cam = F.relu(cam)\n",
    "        # Interpolate to match the width of the input image\n",
    "        # Note: We're only interpolating the width (201) since height is different\n",
    "        cam = F.interpolate(\n",
    "            cam,\n",
    "            size=(input_image.shape[2], input_image.shape[3]),  # (16, 201)\n",
    "            mode='bicubic',\n",
    "            align_corners=False\n",
    "        )\n",
    "        \n",
    "        heatmap = cam.cpu().numpy()[0, 0]\n",
    "        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "        \n",
    "        return heatmap\n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Remove all registered hooks from the target layer.\"\"\"\n",
    "        if hasattr(self.target_layer, \"_forward_hooks\"):\n",
    "            self.target_layer._forward_hooks.clear()\n",
    "        if hasattr(self.target_layer, \"_backward_hooks\"):\n",
    "            self.target_layer._backward_hooks.clear()\n",
    "        if hasattr(self.target_layer, \"_full_backward_hooks\"):\n",
    "            self.target_layer._full_backward_hooks.clear()\n",
    "\n",
    "def apply_heatmap(image: np.ndarray, heatmap: np.ndarray, alpha: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply heatmap overlay to original image.\n",
    "    \n",
    "    Args:\n",
    "        image: Original image (C, H, W) normalized\n",
    "        heatmap: Heatmap array (H, W)\n",
    "        alpha: Transparency factor for overlay\n",
    "    \"\"\"\n",
    "    # Denormalize image to [0,1] range\n",
    "    image = image.copy()\n",
    "    for c in range(image.shape[0]):\n",
    "        channel = image[c]\n",
    "        channel_min, channel_max = channel.min(), channel.max()\n",
    "        image[c] = (channel - channel_min) / (channel_max - channel_min)\n",
    "    \n",
    "    # Convert to (H, W, C)\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    \n",
    "    # Convert heatmap to RGB (H, W, 3)\n",
    "    heatmap_rgb = np.stack([heatmap, np.zeros_like(heatmap), np.zeros_like(heatmap)], axis=-1)\n",
    "    \n",
    "    # Create overlay\n",
    "    overlay = image * (1 - alpha) + heatmap_rgb * alpha\n",
    "    \n",
    "    return overlay\n",
    "remove_all_hooks(model)\n",
    "model = resnet.to(device)\n",
    "# target_layer =  model.layer4[1].conv2\n",
    "target_layer =  model.layer1[1].conv2\n",
    "images = [plot_dataset_80[idx][0] for idx in intermediate_indices]\n",
    "def generate_RAM(model,image,traget_layer):    \n",
    "    model.eval()\n",
    "    grad_cam = GradCAM(model, target_layer) \n",
    "    with torch.no_grad():\n",
    "        image_tensor = image.to(device).unsqueeze(0)  # Add batch dimension\n",
    "    heatmap = grad_cam.generate_heatmap(image_tensor)\n",
    "    grad_cam.remove_hooks()\n",
    "    return heatmap\n",
    "heatmaps = [generate_RAM(model,image,target_layer) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa1e0b-263b-4624-a18d-d8db22ffe5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(image_tensor,heatmap):\n",
    "    # Visualize\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    # Original image - denormalize for visualization\n",
    "    img = image_tensor.cpu().numpy()\n",
    "    img_norm = np.zeros_like(img)\n",
    "    for c in range(img.shape[0]):\n",
    "        channel = img[c]\n",
    "        channel_min, channel_max = channel.min(), channel.max()\n",
    "        img_norm[c] = (channel - channel_min) / (channel_max - channel_min)\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(np.transpose(img_norm, (1,2,0)))\n",
    "    plt.title('Original Image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(heatmap, cmap='jet')\n",
    "    plt.title('Heatmap')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(3, 1, 3)\n",
    "    overlay = apply_heatmap(image_tensor.cpu().numpy(), heatmap)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title('Overlay')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df118d7c-c45a-4471-832f-df68010f966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(images[0],heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9af91a-efc3-4836-87f3-35cdea1eb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(images[2],heatmaps[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a189f85c-8c3d-451a-90b0-1812525c76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(images[3],heatmaps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd659e7-299d-4bf4-bb6f-218d67b56b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(images[-2],heatmaps[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd39387-6705-4eda-a5ad-aa11cdcdd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def test_contrast_sensitivity(model, image, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Applies different contrast values to an image, runs the model, and plots size prediction vs contrast.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model for size prediction.\n",
    "        image: A PIL Image or a torch tensor (C, H, W) in range [0, 1].\n",
    "        device: The device where the model is running ('cpu' or 'cuda').\n",
    "    \"\"\"\n",
    "    contrast_values = np.linspace(0, 1, 50)  # Contrast from 0 (gray) to 2 (high contrast)\n",
    "    predictions = []\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    image = image.to(device) if isinstance(image, torch.Tensor) else TF.to_tensor(image).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for contrast in contrast_values:\n",
    "            adjusted_image = image*contrast \n",
    "            adjusted_image = adjusted_image.unsqueeze(0)  # Add batch dimension\n",
    "            pred = model(adjusted_image).item()\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(contrast_values, predictions, marker='o', linestyle='-')\n",
    "    plt.xlabel(\"Contrast Factor\")\n",
    "    plt.ylabel(\"Predicted Size\")\n",
    "    plt.title(\"Effect of global Contrast change on Size Prediction\")\n",
    "    plt.grid()\n",
    "    plt.show()   \n",
    "    return contrast_values, predictions\n",
    "    \n",
    "contrast_values,predictions = test_contrast_sensitivity(model, images[2], device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iscat",
   "language": "python",
   "name": "iscat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
