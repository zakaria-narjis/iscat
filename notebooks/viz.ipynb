{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a08b531-b828-42c3-9209-cfc8a9900bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(\"Current Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68bc4f1-92bf-4dc3-a987-80b9acbb2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.dataset import iScatDataset\n",
    "from src.data_processing.utils import Utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "DEVICE= 'cuda:7' if torch.cuda.is_available() else 'cpu'\n",
    "data_path_1 = os.path.join('dataset', '2024_11_11', 'Metasurface', 'Chip_02')\n",
    "data_path_2 = os.path.join('dataset', '2024_11_12', 'Metasurface', 'Chip_01')\n",
    "image_paths= []\n",
    "target_paths=[]\n",
    "image_indicies = 12\n",
    "for data_path in [data_path_1,data_path_2]:\n",
    "    i,t = Utils.get_data_paths(data_path,'Brightfield',image_indicies )\n",
    "    image_paths.extend(i)\n",
    "    target_paths.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856443d-2a23-4fd7-b62d-e913e66d49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=256\n",
    "fluo_masks_indices=[1]\n",
    "seg_method = \"comdet\"\n",
    "normalize=False\n",
    "train_dataset = iScatDataset(image_paths[:-2], target_paths[:-2], preload_image=True,image_size = (image_size,image_size),apply_augmentation=True,normalize=normalize,device=DEVICE,fluo_masks_indices=fluo_masks_indices,seg_method=seg_method)\n",
    "valid_dataset = iScatDataset(image_paths[-2:],target_paths[-2:],preload_image=True,image_size = (image_size,image_size),apply_augmentation=False,normalize=normalize,device=DEVICE,fluo_masks_indices=fluo_masks_indices,seg_method=seg_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298bd8a-a476-4e9d-b807-78f3dcd6021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = train_dataset.images.mean(dim=(0,2,3),keepdim=True)\n",
    "STD = train_dataset.images.std(dim=(0,2,3),keepdim=True)\n",
    "del train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6998f5-d58a-4330-aafc-1337630fa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_sample = 3\n",
    "# samples = [valid_dataset[i] for i in range(n_samples)]\n",
    "sample = valid_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d7b46-cf57-473c-8028-47c4e2d3ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_paths = (\n",
    "    'experiments/runs/UNet_Brightfield_2025-01-12_18-05-44',\n",
    "    'experiments/runs/UNet_Brightfield_2025-01-12_19-09-15',\n",
    "    'experiments/runs/UNet_Brightfield_2025-01-12_20-27-14')\n",
    "\n",
    "class MultiClassUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=2, init_features=32):\n",
    "        super(MultiClassUNet, self).__init__()\n",
    "        \n",
    "        # Load the pretrained model and modify the final layer\n",
    "        model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', \n",
    "                               in_channels=in_channels, \n",
    "                               out_channels=1, \n",
    "                               init_features=init_features, \n",
    "                               pretrained=False)\n",
    "        \n",
    "        # Replace the final convolution layer to match number of classes\n",
    "        model.conv = nn.Conv2d(init_features, num_classes, kernel_size=1)\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafe9439-51b1-4c4e-b3f8-6e273df51cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path, num_classes=2,device=DEVICE):\n",
    "    model = MultiClassUNet(in_channels=6, num_classes=num_classes, init_features=64)\n",
    "    checkpoint = torch.load(path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()  \n",
    "    return model\n",
    "    \n",
    "def predict(model, image, mean, std, device)\n",
    "    model.eval()\n",
    "    input_image = image.to(device).unsqueeze(0) # torch.Size([1, 3, 224, 224])\n",
    "    input_image = Utils.z_score_normalize(input_image, mean, std)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)  # Shape: [1, num_classes, 224, 224]\n",
    "    predicted_mask = torch.argmax(output.squeeze(0), dim=0).cpu().numpy()  # Shape: (224, 224)\n",
    "\n",
    "    return predicted_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7267331-fbb7-4c06-b7e5-9ffc1120e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    \"\"\"\n",
    "    Normalize a 16-bit grayscale image to 8-bit for visualization.\n",
    "\n",
    "    Parameters:\n",
    "        image (ndarray): 16-bit grayscale image.\n",
    "\n",
    "    Returns:\n",
    "        ndarray: 8-bit grayscale image.\n",
    "    \"\"\"\n",
    "    image = (image - image.min()) / (image.max() - image.min())  # Normalize to [0, 1]\n",
    "    return (image * 255).astype(np.uint8)  # Scale to [0, 255]\n",
    "\n",
    "def overlay_mask(image, mask, color, alpha=0.5):\n",
    "    \"\"\"Overlays a mask on an image with a specified color and transparency.\"\"\"\n",
    "    if len(image.shape) == 2:\n",
    "        overlay = np.stack([image] * 3, axis=-1)\n",
    "    else:\n",
    "        overlay = image.copy()\n",
    "    for c in range(3):\n",
    "        overlay[:, :, c] = np.where(mask, overlay[:, :, c] * (1 - alpha) + color[c] * alpha, overlay[:, :, c])\n",
    "    return overlay\n",
    "\n",
    "def image_with_masks(image, predicted_mask, ground_truth_mask):\n",
    "    predicted_colors = {\n",
    "        1: (0, 255, 0),      # Green for class 1\n",
    "        2: (0, 0, 255),    # Blue for class 2\n",
    "    }\n",
    "    gt_colors = {\n",
    "        1: (255, 0, 0),      # Red for class 1\n",
    "        2: (255,255, 0),    # Yellow for class 2\n",
    "    }\n",
    "\n",
    "    # Normalize image for visualization\n",
    "    image_normalized = normalize_image(image)\n",
    "    combined_image = image_normalized.copy()\n",
    "\n",
    "    # Overlay masks for each class\n",
    "    for class_label, color in predicted_colors.items():\n",
    "        class_mask = (predicted_mask == class_label)\n",
    "        combined_image = overlay_mask(combined_image, class_mask, color=color, alpha=0.5)\n",
    "\n",
    "    for class_label, color in gt_colors.items():\n",
    "        class_mask = (ground_truth_mask == class_label)\n",
    "        combined_image = overlay_mask(combined_image, class_mask, color=color, alpha=0.5)\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e3e4a-b077-496f-ab2b-767ed665acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for idx, path in enumerate(experiments_paths):\n",
    "    if idx==2:\n",
    "        num_classes=3\n",
    "    else:\n",
    "        num_classes=2\n",
    "    model_path = path+'/best_model.pth'\n",
    "    model = load(model_path,num_classes=num_classes)\n",
    "    pred_mask = predict(model, sample[0], MEAN, STD, DEVICE)\n",
    "    combined = image_with_masks(sample[0], pred_mask , sample[1])\n",
    "    preds.append(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8198121-184f-4fc7-9acb-839f82454504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image and the overlays\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Original image visualization\n",
    "ax1.imshow(image_normalized, cmap='gray')\n",
    "ax1.set_title(\"Cy5:0\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Combined overlay visualization\n",
    "ax2.imshow(combined_image)\n",
    "ax2.set_title(\"FITC:1\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    " \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "legend_elements = []\n",
    "for class_label, color in predicted_colors.items():\n",
    "    legend_elements.append(plt.Line2D([0], [0], color=np.array(color) / 255, lw=4, label=f'Predicted Class {class_label}'))\n",
    "for class_label, color in gt_colors.items():\n",
    "    legend_elements.append(plt.Line2D([0], [0], color=np.array(color) / 255, lw=4, linestyle='dashed', label=f'GT Class {class_label}'))\n",
    "ax2.legend(handles=legend_elements, loc='lower right', fontsize='small')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iscat",
   "language": "python",
   "name": "iscat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
