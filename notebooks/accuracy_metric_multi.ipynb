{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1db905-4309-463b-9bad-717c6aecf234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /workspace/iscat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(\"Current Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30febfda-e39c-4333-b0e8-073e2598fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.dataset import iScatDataset\n",
    "from src.data_processing.utils import Utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "DEVICE= 'cuda:11' if torch.cuda.is_available() else 'cpu'\n",
    "data_path_1 = os.path.join('dataset', '2024_11_11', 'Metasurface', 'Chip_02')\n",
    "data_path_2 = os.path.join('dataset', '2024_11_12', 'Metasurface', 'Chip_01')\n",
    "image_paths= []\n",
    "target_paths=[]\n",
    "image_indicies = 12\n",
    "for data_path in [data_path_1,data_path_2]:\n",
    "    i,t = Utils.get_data_paths(data_path,'Brightfield',image_indicies )\n",
    "    image_paths.extend(i)\n",
    "    target_paths.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b639eda8-b363-42bd-bf9a-589afb497b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images to Memory: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:01<00:00,  7.24it/s]\n",
      "Loading images to Memory: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s]\n"
     ]
    }
   ],
   "source": [
    "image_size=256\n",
    "fluo_masks_indices=[1]\n",
    "seg_method = \"comdet\"\n",
    "normalize=False\n",
    "train_dataset = iScatDataset(image_paths[:-2], target_paths[:-2], preload_image=True,image_size = (image_size,image_size),apply_augmentation=True,normalize=normalize,device=DEVICE,fluo_masks_indices=fluo_masks_indices,seg_method=seg_method)\n",
    "valid_dataset = iScatDataset(image_paths[-2:],target_paths[-2:],preload_image=True,image_size = (image_size,image_size),apply_augmentation=False,normalize=normalize,device=DEVICE,fluo_masks_indices=fluo_masks_indices,seg_method=seg_method)\n",
    "MEAN = train_dataset.images.mean(dim=(0,2,3),keepdim=True)\n",
    "STD = train_dataset.images.std(dim=(0,2,3),keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ad28500f-cbbf-4bcd-9f26-03663ef2b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.v2 import Normalize\n",
    "batch_size=128\n",
    "def create_dataloaders(test_dataset, batch_size=4):\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return val_loader\n",
    "val_loader = create_dataloaders(valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05b2b3a3-1fd5-422d-8944-004c9bd2dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "samples = [valid_dataset[i] for i in range(n_samples)]\n",
    "test_batch = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5475ad6-5461-4efc-b654-c5e58cb69e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_paths = (\n",
    "    'experiments/runs/UNet_Brightfield_2025-01-12_18-05-44',\n",
    "    'experiments/runs/UNet_Brightfield_2025-01-12_19-09-15',\n",
    "    'experiments/runs/UNet_Brightfield_2025-01-12_20-27-14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4c083d-dcae-4c35-b24f-e47e575c0282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.Unet import UNet\n",
    "def load_model(path, num_classes=2,device=DEVICE):\n",
    "    model = UNet(in_channels=12, num_classes=num_classes, init_features=64)\n",
    "    checkpoint = torch.load(path, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()  \n",
    "    return model\n",
    "    \n",
    "def predict(model, image, mean, std, device):\n",
    "    model.eval()\n",
    "    input_image = image.to(device) # torch.Size([1, 3, 224, 224])\n",
    "    input_image = Utils.z_score_normalize(input_image, mean, std)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)  # Shape: [1, num_classes, 224, 224]\n",
    "    predicted_mask = torch.argmax(output, dim=1).cpu().numpy()  # Shape: (224, 224)\n",
    "\n",
    "    return predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abbe0abf-8c78-4f02-8671-2658496cc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "def count_matching_particles_multiclass(\n",
    "    pred_mask: np.ndarray,\n",
    "    gt_mask: np.ndarray\n",
    ") -> Dict[int, Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Count matching particles between prediction and ground truth masks for multiple classes.\n",
    "    \n",
    "    Args:\n",
    "        pred_mask: Multi-class prediction mask (0 for background, 1+ for different particle classes)\n",
    "        gt_mask: Multi-class ground truth mask (0 for background, 1+ for different particle classes)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping class_id to tuple of (true_positives, false_positives, false_negatives)\n",
    "    \"\"\"\n",
    "    # Get unique classes (excluding background class 0)\n",
    "    classes = sorted(set(np.unique(pred_mask)) | set(np.unique(gt_mask)))\n",
    "    classes = [c for c in classes if c != 0]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Process each class separately\n",
    "    for class_id in classes:\n",
    "        # Create binary masks for current class\n",
    "        pred_binary = (pred_mask == class_id).astype(np.int32)\n",
    "        gt_binary = (gt_mask == class_id).astype(np.int32)\n",
    "        \n",
    "        # Label connected components\n",
    "        pred_labeled, num_pred = label(pred_binary)\n",
    "        gt_labeled, num_gt = label(gt_binary)\n",
    "        \n",
    "        # Initialize counters\n",
    "        tp = 0\n",
    "        matched_pred_labels = set()\n",
    "        matched_gt_labels = set()\n",
    "        \n",
    "        # For each predicted particle of current class\n",
    "        for pred_label in range(1, num_pred + 1):\n",
    "            pred_particle = pred_labeled == pred_label\n",
    "            \n",
    "            # Find any overlap with GT particles\n",
    "            overlapping_gt_labels = set(gt_labeled[pred_particle]) - {0}\n",
    "            \n",
    "            if overlapping_gt_labels:\n",
    "                # If there's any overlap, count as TP\n",
    "                tp += 1\n",
    "                matched_pred_labels.add(pred_label)\n",
    "                matched_gt_labels.update(overlapping_gt_labels)\n",
    "        \n",
    "        # Count unmatched predictions as FP and unmatched GT as FN\n",
    "        fp = num_pred - len(matched_pred_labels)\n",
    "        fn = num_gt - len(matched_gt_labels)\n",
    "        \n",
    "        results[class_id] = (tp, fp, fn)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def process_batch_multiclass(\n",
    "    pred_masks: np.ndarray,\n",
    "    gt_masks: np.ndarray\n",
    ") -> Dict[int, Tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Process a batch of masks and aggregate the results.\n",
    "    \n",
    "    Args:\n",
    "        pred_masks: Batch of prediction masks [batch_size, height, width]\n",
    "        gt_masks: Batch of ground truth masks [batch_size, height, width]\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping class_id to aggregated (tp, fp, fn) across the batch\n",
    "    \"\"\"\n",
    "    # Initialize results dictionary\n",
    "    batch_results = {}\n",
    "    \n",
    "    # Process each image in the batch\n",
    "    for pred_mask, gt_mask in zip(pred_masks, gt_masks):\n",
    "        image_results = count_matching_particles_multiclass(pred_mask, gt_mask)\n",
    "        \n",
    "        # Aggregate results for each class\n",
    "        for class_id, (tp, fp, fn) in image_results.items():\n",
    "            if class_id not in batch_results:\n",
    "                batch_results[class_id] = [0, 0, 0]\n",
    "            batch_results[class_id][0] += tp\n",
    "            batch_results[class_id][1] += fp\n",
    "            batch_results[class_id][2] += fn\n",
    "    \n",
    "    # Convert lists to tuples in final results\n",
    "    return {k: tuple(v) for k, v in batch_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fb7d86eb-90c9-4918-bbf0-aeb833b9d698",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "images = test_batch[0].clone()\n",
    "gt_masks = test_batch[1].clone().cpu().numpy()\n",
    "path = experiments_paths[1]\n",
    "model_path = path+'/best_model.pth'\n",
    "model = load_model(model_path,num_classes=2)\n",
    "pred_masks = predict(model, images, MEAN, STD, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e59c15d4-d05b-48e7-9d6a-612a7bdff80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = process_batch_multiclass(pred_masks,gt_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2569d337-cb0e-40b9-ab75-226f2dc4d70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: (788, 238, 39)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19ba0ad5-0ee2-4b9b-905f-858dd0c32c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(824, 724, 923)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50d8d8d1-6e15-4a92-92b6-f4bf11c1637a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7680311890838206\n",
      "0.9528415961305925\n"
     ]
    }
   ],
   "source": [
    "def precision(tp,fp):\n",
    "    return tp/(tp+fp)\n",
    "def recall(tp,fn):\n",
    "    return tp/(tp+fn)\n",
    "print(precision(results[1][0],results[1][1]))\n",
    "print(recall(results[1][0],results[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84350381-6481-418a-a15e-17cabf7cc212",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(precision(results[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m],results[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(recall(results[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m],results[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m2\u001b[39m]))\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "print(precision(results[2][0],results[2][1]))\n",
    "print(recall(results[2][0],results[2][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d2541a2-ee7d-4a81-9b3d-243df3a2b71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6347531096871466\n"
     ]
    }
   ],
   "source": [
    "print(recall(results[2][0]+results[1][0],results[2][2]+results[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a24977f-5b6a-479c-8f6a-3ea346dd68b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639331814730448\n"
     ]
    }
   ],
   "source": [
    "print(precision(results[2][0]+results[1][0],results[2][1]+results[1][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iscat",
   "language": "python",
   "name": "iscat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
