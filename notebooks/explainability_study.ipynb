{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d559d4f-947d-4093-b3c3-926a9b93ea19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: /workspace/iscat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(\"Current Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a99b3a-cc92-49e8-b389-e6efd6ae5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_processing.dataset import iScatDataset\n",
    "from src.data_processing.utils import Utils\n",
    "import torch\n",
    "DEVICE= 'cuda:7' if torch.cuda.is_available() else 'cpu'\n",
    "data_path_1 = os.path.join('dataset', '2024_11_11', 'Metasurface', 'Chip_02')\n",
    "data_path_2 = os.path.join('dataset', '2024_11_12', 'Metasurface', 'Chip_01')\n",
    "image_paths= []\n",
    "target_paths=[]\n",
    "image_indicies = 6\n",
    "for data_path in [data_path_1,data_path_2]:\n",
    "    i,t = Utils.get_data_paths(data_path,'Brightfield',image_indicies )\n",
    "    image_paths.extend(i)\n",
    "    target_paths.extend(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f79ff91-36b8-46ea-b8f6-1046df0a2ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading TIFF images to Memory: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 15.78it/s]\n",
      "Loading TIFF images to Memory: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 18.12it/s]\n"
     ]
    }
   ],
   "source": [
    "image_size=256\n",
    "fluo_masks_indices=[1]\n",
    "seg_method = \"comdet\"\n",
    "normalize=False\n",
    "train_dataset = iScatDataset(image_paths[:-2], target_paths[:-2], preload_image=True,image_size = (image_size,image_size),apply_augmentation=True,normalize=normalize,device=DEVICE,fluo_masks_indices=fluo_masks_indices,seg_method=seg_method)\n",
    "valid_dataset = iScatDataset(image_paths[-2:],target_paths[-2:],preload_image=True,image_size = (image_size,image_size),apply_augmentation=False,normalize=normalize,device=DEVICE,fluo_masks_indices=fluo_masks_indices,seg_method=seg_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fa9a1a-50f1-4495-9d1c-8d499630e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = train_dataset.images.mean(dim=(0,2,3),keepdim=True)\n",
    "STD = train_dataset.images.std(dim=(0,2,3),keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b3a35c-d3cd-4983-8921-e846c70e23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from monai.losses import DiceLoss\n",
    "from monai.metrics import MeanIoU\n",
    "import numpy as np\n",
    "from monai.networks.utils import one_hot\n",
    "import random\n",
    "def set_random_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility in Python, NumPy, PyTorch, and CUDA.\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to use.\n",
    "    \"\"\"\n",
    "    random.seed(seed)  # Python random\n",
    "    np.random.seed(seed)  # NumPy\n",
    "    torch.manual_seed(seed)  # PyTorch CPU\n",
    "    torch.cuda.manual_seed(seed)  # PyTorch GPU\n",
    "    torch.cuda.manual_seed_all(seed)  # PyTorch all GPUs\n",
    "    \n",
    "    # Ensure deterministic behavior (may slow down performance)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def z_score_normalize(images,mean=MEAN,std=STD, eps: float = 1e-8):\n",
    "    normalized_images = (images - mean) / (std + eps)\n",
    "    return normalized_images\n",
    "    \n",
    "miou_metric = MeanIoU(include_background=True, reduction=\"mean\")\n",
    "def compute_metrics(predictions: torch.Tensor, targets: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Compute mean IoU metric\n",
    "    predictions: (batch_size, 1, height, width)\n",
    "    targets: (batch_size, height, width)\n",
    "    \"\"\"\n",
    "\n",
    "    pred_masks = (torch.softmax(predictions,dim=1) > 0.5).float()\n",
    "\n",
    "    # Add channel dimension to targets if needed\n",
    "    if len(targets.shape) == 3:\n",
    "        targets = targets.unsqueeze(1)\n",
    "    pred_one_hot=pred_masks\n",
    "    target_one_hot = torch.cat([1 - targets, targets], dim=1) \n",
    "    # Compute IoU\n",
    "    metric = miou_metric(pred_one_hot, target_one_hot)\n",
    "    \n",
    "    # Return mean IoU (average across classes)\n",
    "    return metric.nanmean().item() \n",
    "        \n",
    "class MultiClassUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1, init_features=32):\n",
    "        super(MultiClassUNet, self).__init__()\n",
    "        \n",
    "        # Load the pretrained model and modify the final layer\n",
    "        model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', \n",
    "                               in_channels=in_channels, \n",
    "                               out_channels=1, \n",
    "                               init_features=init_features, \n",
    "                               pretrained=False)\n",
    "        \n",
    "        # Replace the final convolution layer to match number of classes\n",
    "        model.conv = nn.Conv2d(init_features, num_classes, kernel_size=1)\n",
    "        \n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad74e1b9-541d-4db4-9f21-7971e51d99a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiClassUNet(\n",
       "  (model): UNet(\n",
       "    (encoder1): Sequential(\n",
       "      (enc1conv1): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc1norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc1relu1): ReLU(inplace=True)\n",
       "      (enc1conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc1norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc1relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder2): Sequential(\n",
       "      (enc2conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc2norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc2relu1): ReLU(inplace=True)\n",
       "      (enc2conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc2norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc2relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder3): Sequential(\n",
       "      (enc3conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc3norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc3relu1): ReLU(inplace=True)\n",
       "      (enc3conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc3norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc3relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (encoder4): Sequential(\n",
       "      (enc4conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc4norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc4relu1): ReLU(inplace=True)\n",
       "      (enc4conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (enc4norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (enc4relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (bottleneck): Sequential(\n",
       "      (bottleneckconv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bottlenecknorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneckrelu1): ReLU(inplace=True)\n",
       "      (bottleneckconv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bottlenecknorm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bottleneckrelu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder4): Sequential(\n",
       "      (dec4conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec4norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec4relu1): ReLU(inplace=True)\n",
       "      (dec4conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec4norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec4relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder3): Sequential(\n",
       "      (dec3conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec3norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec3relu1): ReLU(inplace=True)\n",
       "      (dec3conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec3norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec3relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder2): Sequential(\n",
       "      (dec2conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec2norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec2relu1): ReLU(inplace=True)\n",
       "      (dec2conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec2norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec2relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (decoder1): Sequential(\n",
       "      (dec1conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec1norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec1relu1): ReLU(inplace=True)\n",
       "      (dec1conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (dec1norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dec1relu2): ReLU(inplace=True)\n",
       "    )\n",
       "    (conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path_0_3 = \"experiments/runs/UNet_Metasurface_2025-01-10_01-01-59/best_model.pth\"\n",
    "model_path_0_6 = \"experiments/runs/UNet_Metasurface_2025-01-10_15-15-58/best_model.pth\"\n",
    "model_path_1_6 = \"experiments/runs/UNet_Metasurface_2025-01-10_15-46-48/best_model.pth\"\n",
    "model_2 = MultiClassUNet(in_channels=6, num_classes=2, init_features=64)\n",
    "checkpoint = torch.load(model_path_1_6, weights_only=False)\n",
    "model_2.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_2.to(DEVICE)\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c22fb7-c512-493d-b306-c5952daa9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def channel_ablation(model, inputs, targets, channel_idx, device):\n",
    "    input_ = inputs.clone().to(device)\n",
    "    input_ = z_score_normalize(inputs)\n",
    "    ablated_inputs = input_.clone()\n",
    "    ablated_inputs[:, channel_idx, :, :] = 0 \n",
    "    print((ablated_inputs==input_).all())# Set one channel to zero\n",
    "    with torch.no_grad():\n",
    "        abla_outputs = model(ablated_inputs)\n",
    "        outputs = model(input_)\n",
    "    abla_miou = compute_metrics(abla_outputs, targets.clone().to(device))\n",
    "    miou = compute_metrics(outputs, targets.clone().to(device))# Define your loss metric\n",
    "    out = round(abla_miou*100/miou)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05957234-507e-4e98-a390-292c473085de",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=150\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def create_dataloaders(train_dataset, test_dataset, batch_size=4):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "train_loader, val_loader = create_dataloaders(train_dataset, valid_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5eed459-3d54-4d24-b48b-132eb2597270",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_samples,target_samples = next(iter(val_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32d494f1-7a72-40d0-af67-90d70e76c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:7')\n",
      "tensor(False, device='cuda:7')\n",
      "tensor(False, device='cuda:7')\n",
      "tensor(False, device='cuda:7')\n",
      "tensor(False, device='cuda:7')\n",
      "tensor(False, device='cuda:7')\n",
      "miou per channel: [91, 91, 85, 91, 89, 95]\n"
     ]
    }
   ],
   "source": [
    "mious = []\n",
    "for i in range(input_samples.shape[1]):  # Loop over channels\n",
    "    miou = channel_ablation(model_2, input_samples, target_samples, i, DEVICE)\n",
    "    mious.append(miou)\n",
    "print(\"miou per channel:\", mious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84cc46ff-2a09-4018-b620-d436c53d9c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miou per channel: [95, 97, 90, 92, 94, 101]\n"
     ]
    }
   ],
   "source": [
    "print(\"miou per channel:\", mious)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iscat",
   "language": "python",
   "name": "iscat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
